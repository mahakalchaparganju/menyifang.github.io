<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="language" content="english">
<title>Gesture Sense</title>
<meta name="description" content="High Precision Gesture Sensing">
<meta name="author" content="Yifang Men">
<link rel="icon" type="image/x-icon" href="http://www.icst.pku.edu.cn/favicon.ico">
<link rel="stylesheet" type="text/css" href="./Gesture_files/project.css">
</head>

<body>
<div id="main">
  
	<div class="content"><br>
		<h1>High precision gesture sensing via quantitative characterization of the doppler effect</h1>
		<div class="authors">
                  <div class="author">
				 <a href="mailto:aihj@whu.edu.cn">Haojun Ai</a>
			</div>
			<div class="author">
				 <a href="https://menyifang.github.io/" style="text-decoration: none">Yifang Men*</a>
		    </div>
		    
			<div class="author">
				 <a href="mailto:hllrob@163.com" style="text-decoration: none">Liangliang Han</a>
			</div>
			<div class="author">
				 <a href="mailto:whuchaolee@whu.edu.cn" style="text-decoration: none">Zuchao Li</a>
			</div>
                  <div class="author">
				 <a href="mailto:amylmy@whu.edu.cn" style="text-decoration: none">Mengyun Liu</a>
			</div>

	
		</div>
		<br>
	  	<p class="banner" align="center"><em>Accepted by ICPR, Dec 2016. </em></p>
		<div class="overview sec">
			<div class="picture_wrapper">
		  		<img src="./Gesture_files/framework.jpg" width="50%" alt="Teaser">
		  		<p style="text-align: left">Fig.1 The system processing components </p>
	  		</div>
	  	</div>

		<div class="Abstract sec">
			<h2>Abstract</h2>
			<div class="desp">
				<p style="text-align:justify">
				This paper presents a high precision gesture recognition system that leverages the Doppler effect of ultrasound to sense in-air hand gestures. The system can precisely identify a wider variety of gestures than other systems without any modification to consumer laptops. The system recognizes quantitatively detailed and complex movements from the signals reflected by a moving body. A Hidden Markov Model is used to construct a library of independent, discrete gestures. The gestures can be mapped to diverse application actions. Our method can distinguish among similar gestures with slight difference by extracting fewer, more effective features. Our proposed system reduces false positives caused by unintended motions and is versatile and adaptable to multiple device. We implemented a proof-of-concept prototype on a laptop and extensively evaluated the system. Our results show that the system recognizes ten gestures with an average accuracy of 98% and 18 gestures including similar ones with 95% accuracy. The flexibility and robustness on multiple devices highlight its ability to enable future ubiquitous non-contact gesture-based interaction with computing devices.

				</p>
			</div>
			<div align="center" id="pipeline">
		  		<img src="./Gesture_files/define.jpg" width="60%">
		  		<p style="text-align: left">Fig. 2. The definiation of gesture library.</p>
	  		</div>
                  <div align="center" id="pipeline">
		  		<img src="./Gesture_files/results.jpg" width="60%">
		  		<p style="text-align: left">Fig. 3. The accuracy values for five groups containing similar gestures with different feature selection.</p>
	  		</div>

		</div>

		<div class="download sec">
			<h2>Download</h2>
			<div>
				<li><strong>Paper</strong>: <a href="./Gesture_files/Gesture_Sense_ICPR_2016.pdf">pdf</a></li>
				<li><strong>Supplementary Material</strong>: <a href="./CFITT_files/supp.pdf">pdf</a></li>

			</div>
		</div>

		<div class="citation sec">
			<h2>Citation</h2>
			<p class="bibtex">@inproceedings{ai2016high,
&nbsp; title={High precision gesture sensing via quantitative characterization of the doppler effect},
&nbsp; author={Ai, Haojun and Men, Yifang and Han, Liangliang and Li, Zuchao and Liu, Mengyun},
&nbsp; booktitle={2016 23rd International Conference on Pattern Recognition (ICPR)},
&nbsp; pages={973--978},
&nbsp; year={2016},
&nbsp; organization={IEEE}
}
			</p>
		</div>


<!-- 		<div class="experiments sec">
			<h2>Additional Results</h2>
			<div id="images">
				<h3>Action Detection Performance</h3>
				<div align="center" id="table">
					<p>Table 1. F 1?Score on OAD dataset</p>
					<img src='OAD/figures/OAD_table.png' width='50%' >
				</div>
			</div>
		</div>
		<br></br> -->



  </div>
</div>


</body></html>
